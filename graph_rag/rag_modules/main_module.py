
"""
åŸºäºå›¾RAGçš„æ™ºèƒ½çƒ¹é¥ªåŠ©æ‰‹ - ä¸»ç¨‹åº
æ•´åˆä¼ ç»Ÿæ£€ç´¢å’Œå›¾RAGæ£€ç´¢ï¼Œå®ç°çœŸæ­£çš„å›¾æ•°æ®ä¼˜åŠ¿
"""

import os
import sys
import time
import logging
from typing import List, Optional, Dict, Any

# è®¾ç½®æ—¥å¿—
logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(name)s - %(levelname)s - %(message)s')
logger = logging.getLogger(__name__)

sys.path.insert(0, os.path.dirname(os.path.dirname(os.path.abspath(__file__))))

from dotenv import load_dotenv
from config import DEFAULT_CONFIG, GraphRAGConfig
from rag_modules.graph_data_preparation import GraphDataPreparationModule
from rag_modules.milvus_index_construction import MilvusIndexConstructionModule
from rag_modules.generation_integration import GenerationIntegrationModule
from rag_modules.hybrid_retrieval import HybridRetrievalModule
from rag_modules.graph_rag_retrieval import GraphRAGRetrieval
from rag_modules.intelligent_query_router import IntelligentQueryRouter

# åŠ è½½ç¯å¢ƒå˜é‡
load_dotenv()


class AdvancedGraphRAGSystem:
    """
    å›¾RAGç³»ç»Ÿ
    ä¿®æ”¹ï¼šç§»é™¤è‡ªåŠ¨æ„å»ºçŸ¥è¯†åº“ï¼Œæ”¹ä¸ºæ‰‹åŠ¨æ§åˆ¶
    """

    def __init__(self, config: Optional[GraphRAGConfig] = None):
        self.config = config or DEFAULT_CONFIG

        # æ ¸å¿ƒæ¨¡å—
        self.data_module = None
        self.index_module = None
        self.generation_module = None

        # æ£€ç´¢å¼•æ“
        self.traditional_retrieval = None
        self.graph_rag_retrieval = None
        self.query_router = None

        # ç³»ç»ŸçŠ¶æ€
        self.system_ready = False
        self.knowledge_base_loaded = False

    def initialize_system(self):
        """åˆå§‹åŒ–é«˜çº§å›¾RAGç³»ç»Ÿï¼ˆä¸è‡ªåŠ¨æ„å»ºçŸ¥è¯†åº“ï¼‰"""
        logger.info("å¯åŠ¨é«˜çº§å›¾RAGç³»ç»Ÿ...")

        try:
            # 1. æ•°æ®å‡†å¤‡æ¨¡å—
            print("åˆå§‹åŒ–æ•°æ®å‡†å¤‡æ¨¡å—...")
            self.data_module = GraphDataPreparationModule(
                uri=self.config.neo4j_uri,
                user=self.config.neo4j_user,
                password=self.config.neo4j_password,
                database=self.config.neo4j_database
            )

            # 2. å‘é‡ç´¢å¼•æ¨¡å—ï¼ˆä½†ä¸è‡ªåŠ¨æ„å»ºï¼‰
            print("åˆå§‹åŒ–Milvuså‘é‡ç´¢å¼•æ¨¡å—...")
            self.index_module = MilvusIndexConstructionModule(
                host=self.config.milvus_host,
                port=self.config.milvus_port,
                collection_name=self.config.milvus_collection_name,
                dimension=self.config.milvus_dimension,
                model_name=self.config.embedding_model
            )

            # 3. ç”Ÿæˆæ¨¡å—
            print("åˆå§‹åŒ–ç”Ÿæˆæ¨¡å—...")
            self.generation_module = GenerationIntegrationModule(
                model_name=self.config.llm_model,
                temperature=self.config.temperature,
                max_tokens=self.config.max_tokens
            )

            print("âœ… é«˜çº§å›¾RAGç³»ç»Ÿæ¨¡å—åˆå§‹åŒ–å®Œæˆï¼")
            print("âš ï¸  æ³¨æ„ï¼šçŸ¥è¯†åº“éœ€è¦æ‰‹åŠ¨æ„å»º")

        except Exception as e:
            logger.error(f"ç³»ç»Ÿåˆå§‹åŒ–å¤±è´¥: {e}")
            raise

    def load_or_build_knowledge_base(self, force_rebuild: bool = False) -> Dict[str, Any]:
        """
        æ‰‹åŠ¨åŠ è½½æˆ–æ„å»ºçŸ¥è¯†åº“
        
        Args:
            force_rebuild: æ˜¯å¦å¼ºåˆ¶é‡æ–°æ„å»ºï¼ˆåˆ é™¤æ—§æ•°æ®ï¼‰
            
        Returns:
            æ„å»ºç»“æœä¿¡æ¯
        """
        print("\næ£€æŸ¥çŸ¥è¯†åº“çŠ¶æ€...")

        try:
            # æ£€æŸ¥Milvusé›†åˆæ˜¯å¦å­˜åœ¨
            if self.index_module.has_collection() and not force_rebuild:
                print("âœ… å‘ç°å·²å­˜åœ¨çš„çŸ¥è¯†åº“ï¼Œå°è¯•åŠ è½½...")
                if self.index_module.load_collection():
                    print("çŸ¥è¯†åº“åŠ è½½æˆåŠŸï¼")
                    
                    # åŠ è½½å›¾æ•°æ®ä»¥æ”¯æŒå›¾ç´¢å¼•
                    print("åŠ è½½å›¾æ•°æ®ä»¥æ”¯æŒå›¾æ£€ç´¢...")
                    self.data_module.load_graph_data()
                    print("æ„å»ºèœè°±æ–‡æ¡£...")
                    self.data_module.build_recipe_documents()
                    print("è¿›è¡Œæ–‡æ¡£åˆ†å—...")
                    chunks = self.data_module.chunk_documents(
                        chunk_size=self.config.chunk_size,
                        chunk_overlap=self.config.chunk_overlap
                    )

                    self._initialize_retrievers(chunks)
                    
                    result = {
                        "status": "loaded",
                        "message": "ä»ç°æœ‰é›†åˆåŠ è½½æˆåŠŸ",
                        "stats": self._get_knowledge_base_stats()
                    }
                    
                    self.knowledge_base_loaded = True
                    return result
                else:
                    print("âŒ çŸ¥è¯†åº“åŠ è½½å¤±è´¥ï¼Œå¼€å§‹æ„å»º...")

            print("å¼€å§‹æ„å»ºæ–°çš„çŸ¥è¯†åº“...")

            # ä»Neo4jåŠ è½½å›¾æ•°æ®
            print("ä»Neo4jåŠ è½½å›¾æ•°æ®...")
            self.data_module.load_graph_data()

            # æ„å»ºèœè°±æ–‡æ¡£
            print("æ„å»ºèœè°±æ–‡æ¡£...")
            self.data_module.build_recipe_documents()

            # è¿›è¡Œæ–‡æ¡£åˆ†å—
            print("è¿›è¡Œæ–‡æ¡£åˆ†å—...")
            chunks = self.data_module.chunk_documents(
                chunk_size=self.config.chunk_size,
                chunk_overlap=self.config.chunk_overlap
            )

            # æ„å»ºMilvuså‘é‡ç´¢å¼•
            print("æ„å»ºMilvuså‘é‡ç´¢å¼•...")
            if not self.index_module.build_vector_index(chunks):
                raise Exception("æ„å»ºå‘é‡ç´¢å¼•å¤±è´¥")

            # åˆå§‹åŒ–æ£€ç´¢å™¨
            self._initialize_retrievers(chunks)

            # æ˜¾ç¤ºç»Ÿè®¡ä¿¡æ¯
            stats = self._get_knowledge_base_stats()
            self._show_knowledge_base_stats(stats)

            self.knowledge_base_loaded = True
            
            result = {
                "status": "built",
                "message": "çŸ¥è¯†åº“æ„å»ºå®Œæˆ",
                "stats": stats
            }
            
            print("âœ… çŸ¥è¯†åº“æ„å»ºå®Œæˆï¼")
            return result

        except Exception as e:
            logger.error(f"çŸ¥è¯†åº“æ„å»ºå¤±è´¥: {e}")
            self.knowledge_base_loaded = False
            raise

    def unload_knowledge_base(self) -> Dict[str, Any]:
        """
        å¸è½½çŸ¥è¯†åº“ï¼ˆä»å†…å­˜ä¸­ç§»é™¤ï¼‰
        
        Returns:
            å¸è½½ç»“æœä¿¡æ¯
        """
        try:
            if self.index_module:
                self.index_module.close()
            
            # é‡ç½®ç›¸å…³æ¨¡å—
            self.traditional_retrieval = None
            self.graph_rag_retrieval = None
            self.query_router = None
            self.system_ready = False
            self.knowledge_base_loaded = False
            
            logger.info("çŸ¥è¯†åº“å·²å¸è½½")
            return {"status": "success", "message": "çŸ¥è¯†åº“å·²å¸è½½"}
            
        except Exception as e:
            logger.error(f"å¸è½½çŸ¥è¯†åº“å¤±è´¥: {e}")
            return {"status": "error", "message": str(e)}

    def get_knowledge_base_status(self) -> Dict[str, Any]:
        """
        è·å–çŸ¥è¯†åº“çŠ¶æ€
        
        Returns:
            çŠ¶æ€ä¿¡æ¯
        """
        stats = self._get_knowledge_base_stats() if self.data_module else {}
        
        return {
            "knowledge_base_loaded": self.knowledge_base_loaded,
            "system_ready": self.system_ready,
            "milvus_collection_exists": self.index_module.has_collection() if self.index_module else False,
            "stats": stats
        }

    def _initialize_retrievers(self, chunks: List = None):
        """åˆå§‹åŒ–æ£€ç´¢å™¨"""
        print("åˆå§‹åŒ–æ£€ç´¢å¼•æ“...")

        # å¦‚æœæ²¡æœ‰chunksï¼Œä»æ•°æ®æ¨¡å—è·å–
        if chunks is None:
            chunks = self.data_module.chunks or []

        # åˆå§‹åŒ–ä¼ ç»Ÿæ£€ç´¢å™¨
        self.traditional_retrieval = HybridRetrievalModule(
            config=self.config,
            milvus_module=self.index_module,
            data_module=self.data_module,
            llm_client=self.generation_module.client
        )
        self.traditional_retrieval.initialize(chunks)

        # åˆå§‹åŒ–å›¾RAGæ£€ç´¢å™¨
        self.graph_rag_retrieval = GraphRAGRetrieval(
            config=self.config,
            llm_client=self.generation_module.client
        )
        self.graph_rag_retrieval.initialize()

        # åˆå§‹åŒ–æ™ºèƒ½æŸ¥è¯¢è·¯ç”±å™¨
        self.query_router = IntelligentQueryRouter(
            traditional_retrieval=self.traditional_retrieval,
            graph_rag_retrieval=self.graph_rag_retrieval,
            llm_client=self.generation_module.client,
            config=self.config
        )

        self.system_ready = True
        print("âœ… æ£€ç´¢å¼•æ“åˆå§‹åŒ–å®Œæˆï¼")

    def _get_knowledge_base_stats(self) -> Dict[str, Any]:
        """è·å–çŸ¥è¯†åº“ç»Ÿè®¡ä¿¡æ¯"""
        stats = {
            "recipes": 0,
            "ingredients": 0,
            "cooking_steps": 0,
            "documents": 0,
            "chunks": 0,
            "milvus_records": 0
        }
        
        if self.data_module:
            data_stats = self.data_module.get_statistics()
            stats.update(data_stats)
        
        if self.index_module and self.index_module.has_collection():
            milvus_stats = self.index_module.get_collection_stats()
            stats["milvus_records"] = milvus_stats.get("row_count", 0)
        
        return stats

    def _show_knowledge_base_stats(self, stats: Dict[str, Any] = None):
        """æ˜¾ç¤ºçŸ¥è¯†åº“ç»Ÿè®¡ä¿¡æ¯"""
        if stats is None:
            stats = self._get_knowledge_base_stats()
            
        print(f"\nçŸ¥è¯†åº“ç»Ÿè®¡:")
        print(f"   èœè°±æ•°é‡: {stats.get('recipes', 0)}")
        print(f"   é£Ÿææ•°é‡: {stats.get('ingredients', 0)}")
        print(f"   çƒ¹é¥ªæ­¥éª¤: {stats.get('cooking_steps', 0)}")
        print(f"   æ–‡æ¡£æ•°é‡: {stats.get('documents', 0)}")
        print(f"   æ–‡æœ¬å—æ•°: {stats.get('chunks', 0)}")
        print(f"   å‘é‡ç´¢å¼•: {stats.get('milvus_records', 0)} æ¡è®°å½•")
        
        if stats.get('categories'):
            categories = list(stats['categories'].keys())[:10]
            print(f"   ğŸ·ï¸ ä¸»è¦åˆ†ç±»: {', '.join(categories)}")

    def ask_question_with_routing(self, question: str, stream: bool = False, explain_routing: bool = False):
        """
        æ™ºèƒ½é—®ç­”ï¼šè‡ªåŠ¨é€‰æ‹©æœ€ä½³æ£€ç´¢ç­–ç•¥
        """
        if not self.system_ready or not self.knowledge_base_loaded:
            raise ValueError("ç³»ç»Ÿæˆ–çŸ¥è¯†åº“æœªå°±ç»ªï¼Œè¯·å…ˆæ„å»º/åŠ è½½çŸ¥è¯†åº“")

        print(f"\nâ“ ç”¨æˆ·é—®é¢˜: {question}")

        # æ˜¾ç¤ºè·¯ç”±å†³ç­–è§£é‡Šï¼ˆå¯é€‰ï¼‰
        if explain_routing:
            explanation = self.query_router.explain_routing_decision(question)
            print(explanation)

        start_time = time.time()

        try:
            # 1. æ™ºèƒ½è·¯ç”±æ£€ç´¢
            print("æ‰§è¡Œæ™ºèƒ½æŸ¥è¯¢è·¯ç”±...")
            relevant_docs, analysis = self.query_router.route_query(question, self.config.top_k)

            # 2. æ˜¾ç¤ºè·¯ç”±ä¿¡æ¯
            strategy_icons = {
                "hybrid_traditional": "ğŸ”",
                "graph_rag": "ğŸ•¸ï¸",
                "combined": "ğŸ”„"
            }
            strategy_icon = strategy_icons.get(analysis.recommended_strategy.value, "â“")
            print(f"{strategy_icon} ä½¿ç”¨ç­–ç•¥: {analysis.recommended_strategy.value}")
            print(f"ğŸ“Š å¤æ‚åº¦: {analysis.query_complexity:.2f}, å…³ç³»å¯†é›†åº¦: {analysis.relationship_intensity:.2f}")

            # 3. æ˜¾ç¤ºæ£€ç´¢ç»“æœä¿¡æ¯
            if relevant_docs:
                doc_info = []
                for doc in relevant_docs:
                    recipe_name = doc.metadata.get('recipe_name', 'æœªçŸ¥å†…å®¹')
                    search_type = doc.metadata.get('search_type', doc.metadata.get('route_strategy', 'unknown'))
                    score = doc.metadata.get('final_score', doc.metadata.get('relevance_score', 0))
                    doc_info.append(f"{recipe_name}({search_type}, {score:.3f})")

                print(f"ğŸ“‹ æ‰¾åˆ° {len(relevant_docs)} ä¸ªç›¸å…³æ–‡æ¡£: {', '.join(doc_info[:3])}")
                if len(doc_info) > 3:
                    print(f"    ç­‰ {len(relevant_docs)} ä¸ªç»“æœ...")
            else:
                # ä¿æŒè¿”å›å€¼ç­¾åä¸€è‡´ï¼šå§‹ç»ˆè¿”å› (result, analysis)
                return "æŠ±æ­‰ï¼Œæ²¡æœ‰æ‰¾åˆ°ç›¸å…³çš„çƒ¹é¥ªä¿¡æ¯ã€‚è¯·å°è¯•å…¶ä»–é—®é¢˜ã€‚", analysis

            # 4. ç”Ÿæˆå›ç­”
            print("ğŸ¯ æ™ºèƒ½ç”Ÿæˆå›ç­”...")

            if stream:
                try:
                    for chunk_text in self.generation_module.generate_adaptive_answer_stream(question, relevant_docs):
                        print(chunk_text, end="", flush=True)
                    print("\n")
                    result = "æµå¼è¾“å‡ºå®Œæˆ"
                except Exception as stream_error:
                    logger.error(f"æµå¼è¾“å‡ºè¿‡ç¨‹ä¸­å‡ºç°é”™è¯¯: {stream_error}")
                    print(f"\nâš ï¸ æµå¼è¾“å‡ºä¸­æ–­ï¼Œåˆ‡æ¢åˆ°æ ‡å‡†æ¨¡å¼...")
                    # ä½¿ç”¨éæµå¼ä½œä¸ºåå¤‡
                    result = self.generation_module.generate_adaptive_answer(question, relevant_docs)
            else:
                result = self.generation_module.generate_adaptive_answer(question, relevant_docs)

            # 5. æ€§èƒ½ç»Ÿè®¡
            end_time = time.time()
            print(f"\nâ±ï¸ é—®ç­”å®Œæˆï¼Œè€—æ—¶: {end_time - start_time:.2f}ç§’")

            return result, analysis

        except Exception as e:
            logger.error(f"é—®ç­”å¤„ç†å¤±è´¥: {e}")
            return f"æŠ±æ­‰ï¼Œå¤„ç†é—®é¢˜æ—¶å‡ºç°é”™è¯¯ï¼š{str(e)}", None

    def run_interactive(self):
        """è¿è¡Œäº¤äº’å¼é—®ç­”"""
        if not self.system_ready or not self.knowledge_base_loaded:
            print("âŒ ç³»ç»Ÿæˆ–çŸ¥è¯†åº“æœªå°±ç»ªï¼Œè¯·å…ˆæ„å»º/åŠ è½½çŸ¥è¯†åº“")
            return

        print("\næ¬¢è¿ä½¿ç”¨å°å°å’¸æ·¡RAGçƒ¹é¥ªåŠ©æ‰‹ï¼")
        print("å¯ç”¨åŠŸèƒ½ï¼š")
        print("   - 'stats' : æŸ¥çœ‹ç³»ç»Ÿç»Ÿè®¡")
        print("   - 'load' : åŠ è½½/æ„å»ºçŸ¥è¯†åº“")
        print("   - 'unload' : å¸è½½çŸ¥è¯†åº“")
        print("   - 'quit' : é€€å‡ºç³»ç»Ÿ")
        print("\n" + "=" * 50)

        while True:
            try:
                user_input = input("\næ‚¨çš„é—®é¢˜: ").strip()

                if not user_input:
                    continue

                if user_input.lower() == 'quit':
                    break
                elif user_input.lower() == 'stats':
                    self._show_system_stats()
                    continue
                elif user_input.lower() == 'load':
                    try:
                        result = self.load_or_build_knowledge_base()
                        print(f"âœ… {result['message']}")
                    except Exception as e:
                        print(f"âŒ åŠ è½½å¤±è´¥: {e}")
                    continue
                elif user_input.lower() == 'unload':
                    result = self.unload_knowledge_base()
                    print(f"âœ… {result['message']}")
                    continue

                # æ™®é€šé—®ç­” - ä½¿ç”¨é»˜è®¤è®¾ç½®
                use_stream = True  # é»˜è®¤ä½¿ç”¨æµå¼è¾“å‡º
                explain_routing = True  # é»˜è®¤ä¸æ˜¾ç¤ºè·¯ç”±å†³ç­–

                print("\nå›ç­”:")

                result, analysis = self.ask_question_with_routing(
                    user_input,
                    stream=use_stream,
                    explain_routing=explain_routing
                )

                if not use_stream and result:
                    print(f"{result}\n")

            except KeyboardInterrupt:
                break
            except Exception as e:
                print(f"å¤„ç†é—®é¢˜æ—¶å‡ºé”™: {e}")
                import traceback
                traceback.print_exc()

        print("\nğŸ‘‹ æ„Ÿè°¢ä½¿ç”¨å°å°å’¸æ·¡RAGçƒ¹é¥ªåŠ©æ‰‹ï¼")
        self._cleanup()

    def _show_system_stats(self):
        """æ˜¾ç¤ºç³»ç»Ÿç»Ÿè®¡ä¿¡æ¯"""
        print("\nç³»ç»Ÿè¿è¡Œç»Ÿè®¡")
        print("=" * 40)

        # ç³»ç»ŸçŠ¶æ€
        status = self.get_knowledge_base_status()
        print(f"ç³»ç»Ÿå°±ç»ª: {status['system_ready']}")
        print(f"çŸ¥è¯†åº“å·²åŠ è½½: {status['knowledge_base_loaded']}")
        print(f"Milvusé›†åˆå­˜åœ¨: {status['milvus_collection_exists']}")

        if status['knowledge_base_loaded']:
            # è·¯ç”±ç»Ÿè®¡
            route_stats = self.query_router.get_route_statistics() if self.query_router else {}
            total_queries = route_stats.get('total_queries', 0)

            if total_queries > 0:
                print(f"\nè·¯ç”±ç»Ÿè®¡:")
                print(f"æ€»æŸ¥è¯¢æ¬¡æ•°: {total_queries}")
                print(f"ä¼ ç»Ÿæ£€ç´¢: {route_stats.get('traditional_count', 0)} ({route_stats.get('traditional_ratio', 0):.1%})")
                print(f"å›¾RAGæ£€ç´¢: {route_stats.get('graph_rag_count', 0)} ({route_stats.get('graph_rag_ratio', 0):.1%})")
                print(f"ç»„åˆç­–ç•¥: {route_stats.get('combined_count', 0)} ({route_stats.get('combined_ratio', 0):.1%})")
            else:
                print("\næš‚æ— æŸ¥è¯¢è®°å½•")

            # çŸ¥è¯†åº“ç»Ÿè®¡
            self._show_knowledge_base_stats(status.get('stats'))

    def _cleanup(self):
        """æ¸…ç†èµ„æº"""
        if self.data_module:
            self.data_module.close()
        if self.traditional_retrieval:
            self.traditional_retrieval.close()
        if self.graph_rag_retrieval:
            self.graph_rag_retrieval.close()
        if self.index_module:
            self.index_module.close()
